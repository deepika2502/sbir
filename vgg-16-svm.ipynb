{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network","metadata":{"id":"3DR-eO17geWu"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tue May 18 11:04:44 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importing the libraries","metadata":{"id":"EMefrVPCg-60"}},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, ResNet50, InceptionResNetV2, MobileNet\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport os\n","metadata":{"id":"sCV30xyVhFbE","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"id":"FIleuCAjoFD8","trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.4.1'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Part 1 - Data Preprocessing","metadata":{"id":"oxQxCBWyoGPE"}},{"cell_type":"markdown","source":"\n### Preprocessing the Training set","metadata":{"id":"MvE-heJNo3GG"}},{"cell_type":"code","source":"#Read images and convert them to arrays\ntrain_images = []\ntrain_lables = []\nfor directory_path in glob.glob(\"../input/sbir151/data/train/*\"):\n    lables = directory_path.split(\"/\")[-1]\n    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        train_images.append(img)\n        train_lables.append(lables)\ntrain_images = np.array(train_images)\ntrain_lables = np.array(train_lables)","metadata":{"id":"0koUcJMJpEBD","trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"\n\n### Preprocessing the Test set","metadata":{"id":"mrCMmGw9pHys"}},{"cell_type":"code","source":"#Read images and convert them to arrays\ntest_images = []\ntest_lables = []\nfor directory_path in glob.glob(\"../input/sbir151/data/val/*\"):\n    lables = directory_path.split(\"/\")[-1]\n    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        test_images.append(img)\n        test_lables.append(lables)\ntest_images = np.array(test_images)\ntest_lables = np.array(test_lables)\n","metadata":{"id":"SH4WzfOhpKc3","trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Creating an encoding for the class labels\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(test_lables)\ntest_lables_en = le.transform(test_lables)\nle.fit(train_lables)\ntrain_lables_en = le.transform(train_lables)","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Assign training, testing images and the labels\nx_train,y_train,x_test,y_test = train_images,train_lables_en,test_images,test_lables_en","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Model to deduce the features\nmodel = VGG16 (weights='imagenet',include_top=False,input_shape=(100,100,3))\n\nfor layer in model.layers:\n    layer.trainable = True","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Obtain the features which will be reduces numpy arrays\nimport sys\nimport numpy\nfeature_extractor = model.predict(x_train)\nprint(feature_extractor)\nshape =feature_extractor.shape\nprint(shape)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[[[[ 5.4813166  0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.        19.296404\n     0.       ]\n   [ 0.         0.         0.        ...  0.        32.616196\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         3.983268\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]]\n\n\n [[[26.903156   0.         0.        ...  0.         0.\n     0.       ]\n   [25.941378   0.         0.        ...  0.         0.\n     0.       ]\n   [10.386929   0.         0.        ...  0.        11.585324\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         6.3282504\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]]\n\n\n [[[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.        10.477056\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]]\n\n\n ...\n\n\n [[[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 3.4252815  0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.        14.32931\n     0.       ]]]\n\n\n [[[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.        22.24596    0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.        46.69994    0.        ...  0.         0.\n     0.       ]\n   [ 0.        13.705811   0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.        19.802517   0.        ...  0.         0.\n     0.       ]\n   [ 0.         3.651759   0.        ...  0.         0.\n     0.       ]]]\n\n\n [[[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]]\n\n  [[ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         0.\n     0.       ]\n   [ 0.         0.         0.        ...  0.         7.9943686\n     0.       ]]]]\n(38250, 3, 3, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"#reshaping to 2d array\nfeature = feature_extractor.reshape(feature_extractor.shape[0],-1)\nprint(feature)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[[ 5.4813166  0.         0.        ...  0.         0.         0.       ]\n [26.903156   0.         0.        ...  0.         0.         0.       ]\n [ 0.         0.         0.        ...  0.         0.         0.       ]\n ...\n [ 0.         0.         0.        ...  0.        14.32931    0.       ]\n [ 0.         0.         0.        ...  0.         0.         0.       ]\n [ 0.         0.         0.        ...  0.         7.9943686  0.       ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Using SVM to train on the features extracted using the pretrained architecture\nfrom sklearn import svm\nsvmmodel = svm.SVC(kernel='linear',verbose=True)\nsvmmodel.fit(feature,y_train)\nsvmmodel.score(feature,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[LibSVM]","output_type":"stream"}]},{"cell_type":"code","source":"#Predicting with the classifier model\npredicted_train = svmmodel.predict(feature)\npredicted_train = le.inverse_transform(predicted_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\ns = pickle.dump(svmmodel,open('../working/svm_vgg_16.h5', 'wb'))\nprint(predicted_train)\nprint(le.inverse_transform(y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report, ConfusionMatrixDisplay\nprint('~~~~~~~ TRAINING ~~~~~~~')\nprint(\"Accuracy = \", accuracy_score(train_lables, predicted_train))\n\nreport = classification_report(le.inverse_transform(y_train), predicted_train)\nprint(report)\n\nprint('Confusion Matrix :')\nstring1=\"airplane,apple,banana,bicycle,car,cat,chair,duck,teddy bear,pizza,fire hydrant,train,elephant,knife,cup\"\nclass_names=sorted(list(string1.split(\",\")))\nconfusion_matrix=confusion_matrix(train_lables,predicted_train,labels=class_names)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.subplots(figsize=(15,15))\n\nseaborn1=sns.heatmap(confusion_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, annot_kws={'size': 10},cmap='Blues')\n\n# Save confusion matrix and report\nresults_path = '../working/train_confusion_vgg.png'\nplt.savefig(results_path)\nreport_path = '../working/training_report_vgg.txt'\ntext_file = open(report_path, \"w\")\nn = text_file.write(report)\ntext_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features_extractor =model.predict(x_test)\ntest_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_output = svmmodel.predict(test_feature)\npredicted_output = le.inverse_transform(predicted_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint('~~~~~~~ TESTING ~~~~~~~')\nprint(\"Accuracy = \", accuracy_score(test_lables, predicted_output))\nfrom sklearn.metrics import classification_report\nreport = classification_report(le.inverse_transform(y_test), predicted_output)\nprint(report)\n\nconfusion_matrix=confusion_matrix(le.inverse_transform(y_test), predicted_output)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.subplots(figsize=(15,15))\nstring1=\"airplane,apple,banana,bicycle,car,cat,chair,duck,teddy bear,pizza,fire hydrant,train,elephant,knife,cup\"\nclass_names=sorted(list(string1.split(\",\")))\n\nseaborn1=sns.heatmap(confusion_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, annot_kws={'size': 10},cmap='Blues')\n\n# Save confusion matrix and report\nresults_path = '../working/test_confusion_vgg.png'\nplt.savefig(results_path)\nreport_path = '../working/testing_report_vgg.txt'\ntext_file = open(report_path, \"w\")\nn = text_file.write(report)\ntext_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images = []\nval_lables = []\nfor directory_path in glob.glob(\"../input/sbir151/data/test/*\"):\n    lables = directory_path.split(\"/\")[-1]\n    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        val_images.append(img)\n        val_lables.append(lables)\nval_images = np.array(val_images)\nval_lables = np.array(val_lables)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_features_extractor = model.predict(val_images)\nval_feature = val_features_extractor.reshape(val_features_extractor.shape[0],-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npredicted_output_val = svmmodel.predict(val_feature)\npredicted_output_val = le.inverse_transform(predicted_output_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint('~~~~~~ Validation ~~~~~~~')\nprint(\"Accuracy = \", accuracy_score(val_lables, predicted_output_val))\nfrom sklearn.metrics import classification_report\nreport = classification_report(val_lables, predicted_output_val)\nprint(report)\nprint('Confusion Matrix :')\nconfusion_matrix=confusion_matrix(val_lables,predicted_output_val)\nprint(confusion_matrix)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.subplots(figsize=(15,15))\nstring1=\"airplane,apple,banana,bicycle,car,cat,chair,duck,teddy bear,pizza,fire hydrant,train,elephant,knife,cup\"\nclass_names=sorted(list(string1.split(\",\")))\n\nseaborn1=sns.heatmap(confusion_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, annot_kws={'size': 10},cmap='Blues')\n\n# Save confusion matrix and report\nresults_path = '../working/valid_confusion_vgg.png'\nplt.savefig(results_path)\nreport_path = '../working/validation_vgg.txt'\ntext_file = open(report_path, \"w\")\nn = text_file.write(report)\ntext_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=np.random.randint(0, x_test.shape[0])\nimg = x_test[n]\nplt.imshow(img)\ninput_img = np.expand_dims(img, axis=0)\ninput_img_feature = model.predict(input_img)\ninput_img_features = input_img_feature.reshape(input_img_feature.shape[0],-1)\nprediction_SVM = svmmodel.predict(input_img_features)[0]\nprediction_SVM = le.inverse_transform([prediction_SVM])\nprint('Predicted Label:')\nprint(prediction_SVM)\nprint('Actual Label:')\nprint(test_lables[n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport os,pickle, matplotlib.pyplot as plt\nmodel = VGG16(weights='imagenet',include_top=False,input_shape=(100,100,3))\n\nwith open('../input/model11/svm-vgg-16.h5', 'rb') as file:\n    cnn = pickle.load(file)\nstring1=\"airplane,apple,banana,bicycle,car,cat,chair,duck,teddy bear,pizza,fire hydrant,train,elephant,knife,cup\"\nclass_names=sorted(list(string1.split(\",\")))\nimg = cv2.imread('../input/sbir151/data/val/fire_hydrant/1206.png')\nplt.imshow(img)\ninput_img = np.expand_dims(img, axis=0)\ninput_img_feature = model.predict(input_img)\ninput_img_features = input_img_feature.reshape(input_img_feature.shape[0],-1)\nprediction_SVM = cnn.predict(input_img_features)[0]\nprediction=class_names[prediction_SVM]\nprint('Predicted Label:')\nprint(prediction)\nprint('Actual Label:')\nprint('Fire_Hydrant')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=np.random.randint(0, x_test.shape[0])\nimg = x_test[n]\nplt.imshow(img)\ninput_img = np.expand_dims(img, axis=0)\ninput_img_feature = model.predict(input_img)\ninput_img_features = input_img_feature.reshape(input_img_feature.shape[0],-1)\nprediction_SVM = svmmodel.predict(input_img_features)[0]\nprediction_SVM = le.inverse_transform([prediction_SVM])\nprint('Predicted Label:')\nprint(prediction_SVM)\nprint('Actual Label:')\nprint(test_lables[n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}